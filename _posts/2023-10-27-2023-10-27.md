---
layout: post
title: 2023.10.27
date: 2023-10-27 00:01 -0500
categories: "Interesting Articles"
tags: 2023
---

You don't have to read it, but you just might learn something.

<!--more-->

## Leading Thought

![Quote from Leonard Cohen: Recognize that your struggle and your suffering is the same as everyone else’s, I think that’s the beginning of a responsible life. Otherwise, we are in a continual savage battle with each other with no possible solution, political, social, or spiritual.](../../../assets/img/self-documenting/cohen.png){: width="500"  .left-no-float }

---

## Prime

### [Police surveillance and facial recognition: Why data privacy is imperative for communities of color ](https://www.brookings.edu/articles/police-surveillance-and-facial-recognition-why-data-privacy-is-an-imperative-for-communities-of-color/)

This is an important read for everyone. 

In the book **1984**, we know that people are watched constantly, including in their homes. the general assumption (I think) is that the government has placed them there for surveillance. But What if that *wasn't* the case? What if people brought them into their homes *voluntarily*? This is the way things are working out in the world, and especially the US.

With devices like Ring doorbells, IOT cameras for internal home security or baby/child monitoring, or even video calling devices from Amazon or TVs with built in cameras, more data than ever is being offered up for consumption by law enforcement by way of private companies. The scary part is that our laws and regulations haven't caught up to the reality of this situation.

Following 9/11, we gave up a lot of freedoms n the name of security, and this is the same justification used for police accessing private data without a warrant. The surge of AI systems that are being used with biased algorithms -- especially facial recognition -- means that we place ourselves in danger from misused data vs. that from crime. If you have doubts that the underlying data used by these systems is problematic at best, give the book *[**Biased**](https://www.penguinrandomhouse.com/books/557462/biased-by-jennifer-l-eberhardt-phd/) a read. You just may change your mind about where we're headed.

> When the European Parliament voted in favor of a non-binding resolution last October to prevent the mass police use of facial recognition in public places within the European Union (EU), it acknowledged this dilemma: “AI applications may offer great opportunities in the field of law enforcement…thereby contributing to the safety and security of EU citizens, while at the same time they may entail significant risks for the fundamental rights of people.”

### [Bosses want people back in the office, but employees are finding a workaround—it’s called ‘coffee badging’](https://www.cnbc.com/2023/10/05/as-return-to-office-mandates-pick-up-employees-find-coffee-badging-workaround.html)

Thanks to [Stan Tarosky](https://www.linkedin.com/in/stan-tarosky-2a844677/) for posting this to LinkedIn. I've posted a lot of different points around back to office policies and the impact on employees, as well as the limiting factors on-site only policies have on companies. This, though, may be the first *official* report I've seem about what seems to be *malicious compliance* with on-office requirements (though the article spins in more positively). 

Like anything, I don't think there's a one-size-fits-all solution for everyone. There are extroverts who thrive on in-person work because of the people. Then there are introverts whose lives are miserable in the context of open office plans. There are those with ADHD, for whom being in an office is simply one shiny thing after another, killing any hope of being productive. And there are other neuro-atypicals for whom social interaction isn't even an afterthought. But, just maybe, this is a better solution than most: using mandatory in-office time as more of a social hour and leaving it for relationship building so that people are able to be most-productive when and how it makes sense for them. 

> “This isn’t grade school,” he adds. “We’re not hiring people to watch them work. We’re hiring them to do a job. And it’s the culture of accountability and leadership setting the right tone to be able to measure productivity that makes all the difference here.”

### [This new data poisoning tool lets artists fight back against generative AI](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)

If you have kids -- or maybe you were told this yourself -- it's likely you say things like *it's not OK to hit*. Then, while they are at school, or on the playground, they get picked on by another kid, who maybe hits them and we shift, just a bit, to *it's not OK to hit, unless someone hits you first.* And it makes sense, right? In an ideal world, we want everyone to be respectful of everyone else. Going a step further, you get your child enrolled in martial arts where they learn how to potentially really hurt someone and, when they fight back, end up putting a bully in a wheelchair by accident. did the bully deserve that result?

Morality, to say the least, is complex.

Now imagine you're an artist (or even an author) whose work has been ingested by a company without permission for the purpose of training an AI system. The company is *technically* not selling the artist's work, but is gaining from its use, regardless. Is this OK, not OK, or in some nebulous *gray area*? If it's not OK, similar to someone hitting you, is it OK to hit back? What if that hit results in a permanent incapacitation of the system? Is this wrong for an artist to intentionally poison their work in an attempt to defend themselves from a bully company that didn't ask permission or pay to use the work to train their models? Is it simply a way to deter a bully from picking on you, similar to your kid letting it be known they are taking Karate?

Definitely some interesting questions to ponder given that not all of our laws have caught up to technology. Thanks to [Hannah Sartell](https://www.linkedin.com/in/hanneloresartell/) for pointing me to this article.

> Poisoned data samples can manipulate models into learning, for example, that images of hats are cakes, and images of handbags are toasters. The poisoned data is very difficult to remove, as it requires tech companies to painstakingly find and delete each corrupted sample. 

[Return to Top](#leading-thought)

---

## Humble Bundles

### [Programming MEGA Bundle 2023 Book Bundle](https://www.humblebundle.com/books/programming-mega-bundle-2023-packt-books)

New offering from [Humble Bundle](https://www.humblebundle.com/) benefitting [Child’s Play Charity](https://childsplaycharity.org/) -- and, if you don't know it's there, there is an *Adjust Donation* button that will let you give more of the take to charity! For a minimum donation of $18 you get 16 titles, including:

* Get Your Hands Dirty on Clean Architecture - Second Edition
* Fundamentals for Self-Taught Programmers
* Event-Driven Architecture in Golang
* Test Automation Engineering Handbook
* Test-Driven Development in Go
* And more!

### [Data Science Book Bundle](https://www.humblebundle.com/books/data-science-no-starch-press-books)

New offering from [Humble Bundle](https://www.humblebundle.com/) benefitting [Electronic Frontier Foundation](https://www.eff.org) -- and, if you don't know it's there, there is an *Adjust Donation* button that will let you give more of the take to charity! For a minimum donation of $36 you get 18 titles, including:

* Dive Into Data Science
* MySQL Crash Course
* Practical SQL, 2nd Edition
* The Book of F#
* Python for Data Science
* And more!

[Return to Top](#leading-thought)

---

## Engineering

### [Learning Rust Series](https://dev.to/fadygrab/series/23244)

Looking to learn a new language, or just curious about Rust? This may be a series for you!

### [Docker Volumes](https://refine.dev/blog/docker-volumes/)

Using Docker but not sure how to persist your data beyond the life of the container? Already know about Volumes but can use a refresher? This is an easy-to-understand write-up of the major concepts around Docker Volumes. 

[Return to Top](#leading-thought)

---

## Teams

### [When Employees Tell You They’re Burned Out ](https://www.shrm.org/resourcesandtools/hr-topics/employee-relations/pages/when-employees-tell-you-theyre-burned-out-.aspx)

This is article from the society for Human Resource Managers (SHRM) and the Harvard Business Review is aimed at managers and leaders, but there's some good take-aways for everyone. 

You may be feeling less enthusiastic about your work, or maybe you've noticed this in your team mates. Is it burnout or something else? We all experience ups and downs in our life, both personally and professionally, but sometimes there is a need for intervention. As an employer and team mate, it's important to recognize when people are struggling; this article just may help you help someone else, or understand how to ask for help.

> Burnout is affecting both leaders and employees—and contributing to a talent shortage that's challenging and costly to navigate. When an employee comes to you saying they're burned out, you need to be prepared to deal with it. 

### [Mitigating Employee Burnout: 6 Action Items for Managers](https://www.indeed.com/hire/c/info/employees-burnout)

This is another good look at what burnout is, why it happens, and some strategies to mitigate it. The key to everything in being a successful leader is to be aware of your employees as people, and empathize (not sympathize) with them. Building a high-trust environment will make it easier for them to come to you when trouble is on the horizon rather than sucking it up and leaving with little to no notice.

> Employers who ignore burnout often encounter unusually high job dissatisfaction and employee turnover rates.

[Return to Top](#leading-thought)

---
